\chapter{Música con programación}

\section{Máquinas para música}

Podrías preguntarte: ¿por qué usar un lenguaje de programación para hacer música? e inmediatamente responderte con otra pregunta: ¿por qué no?

Antes de que fuera práctico hacer música electrónica con computadoras, los medios para generar y medir sonidos consistían en circuitos analógicos conectados con cables y controlados con niveles de voltaje. Los primeros usuarios de dichas máquinas no fueron músicos o compositores, sino científicos para quienes eran necesarios ciertos medios a fin de realizar experimentos. 

El uso de máquinas electrónicas para hacer música fue impulsado gracias a los esfuerzos de compositores como \href{https://es.wikipedia.org/wiki/Pierre_Schaeffer} {\textbf{Pierre Schaeffer}} o \href{https://es.wikipedia.org/wiki/Karlheinz_Stockhausen}{\textbf{Karlheinz Stockhausen}}, que dedicaron gran parte de su práctica artística a expandir posibilidades sonoras y a desarrollar junto con ingenieros nuevos instrumentos electrónicos.   

Posteriormente, alrededor de los años 60, pioneros como \href{https://es.wikipedia.org/wiki/Robert_Moog}{\textbf{Bob Moog}} y \href{https://es.wikipedia.org/wiki/Don_Buchla}{\textbf{Don Buchla}} produjeron máquinas analógicas específicamente para propósitos musicales y popularizaron su uso en todo tipo de géneros. 

Lógicamente, una vez el poder de procesamiento y las interfaces para computadoras evolucionaron lo suficiente, la producción de música electrónica comenzó a trasladarse a medios digitales. Pioneros en este campo como \href{https://es.wikipedia.org/wiki/Gottfried_Michael_Koenig} {\textbf{Gottfried Michael Koenig}} y \href{https://es.wikipedia.org/wiki/Iannis_Xenakis} {\textbf{Iannis Xenakis}} realizaron conceptos e ideas radicales que transformaron el modo en el que escuchamos y producimos música.

\section{Medios}

Existen numerosos predecesores de los programas y aplicaciones para audio actuales, entre ellos Kyma\footnote{http://kyma.symbolicsound.com/}, Common Music\footnote{http://commonmusic.sourceforge.net/} y CSound\footnote{http://csound.github.io/}, que fueron creados en los años 80. Estos programas son ambientes de programación y siguen en uso hoy. El paradigma para hacer música en computadoras cambió con la introducción de la línea de tiempo tradicional e interfaces más amigables como en programas como Ableton Live, Logic o Pro Tools.

En esencia, estos programas no son sino código disfrazado con interfaces más accesibles. La desventaja es que, si creamos música exclusivamente con estas herramientas y tenemos una idea que no forma parte del programa, ¡no podemos realizar nuestra idea! Usar un lenguaje de programación para hacer música y sonidos nos da libertad absoluta para implementar ideas que de otra forma no son posibles. 

Programar no es para todo el mundo y eso está bien, porque a veces no necesitamos profundizar tanto en algo para tener resultados. Sin embargo, si sientes que los métodos tradicionales para realizar música no te satisfacen, \href{http://supercollider.github.io/}{\textbf{SuperCollider}} es una herramienta perfecta para experimentar.

\section{Música con computadoras}

Existen obvias y no tan obvias diferencias entre hacer música con medios puramente acústicos, medios electrónicos analógicos y computadoras. ¿Qué es especial acerca de hacer música con computadoras?

\begin{itemize}
\item Velocidad de ejecución
\item Precisión
\item Exploración de ideas formalizadas
\item Experimentación con varios modelos compositivos
\item Experimentación con procesos generativos
\item Creación y re-utilización de instrumentos sonoros
\end{itemize}

En esencia, hacer cosas que sin una computadora son imposibles de realizar. En el proceso, la computadora puede tomar vario roles. Podría ser por ejemplo:

\begin{itemize}
\item Una herramienta para composición
\item Un generador de material sonoro
\item Un asistente para organizar material sonoro
\item Un asistente para transformación de material (efectos)
\item Un performer automático, supervisado o no
\item Un medio para analizar música 
\item Un instrumento musical 
\item Un medio para reproducir música
\end{itemize}

\section{Programación y música}

Cuando comenzamos a trabajar con música generada con computadoras, nuestras percepciones cambian y eventualmente desarrollamos un nuevo oído musical. Sonidos que antes no nos parecían especiales comienzan a interesarnos y nuevas estructuras sonoras se forman en nuestra cabeza. Nuestra sensitividad también muta, poco a poco somos capaces de escuchar más y mejor, pues los detalles que podemos controlar y a los que tenemos que prestar atención al componer música digital son en muchos casos más finos y sutiles que al lidiar con instrumentos convencionales. Nuevas preguntas aparecen y nuestras pre-concepciones sobre lo que es musical se aligeran. 

Por ejemplo podemos empezar a preguntarnos: ¿hay diferencias entre componer música y componer sonidos? Sin notas definidas, ¿tiene sentido concebir música más alla de escalas y ritmos? ¿podemos controlar sonidos en niveles de tiempo menores al de la nota más rápida? Citando al compositor islandés Bjarni Gunnarsson, quien es a propósito un brillante usuario de SuperCollider:

\begin{quote}
Could we think of the sounds a music creates instead of which music sounds create? \footnote{¿Sería posible pensar en los sonidos que una música crea en lugar de qué música los sonidos crean?}
\end{quote}

Generar arte con algoritmos tiene consecuencias en nuestra forma de pensar y nuestra estética, por esto no es soprendente que nuestro trabajo cambie, a veces drásticamente, una vez que dominamos cierta herramienta. En nuestro caso, esta herramienta es SuperCollider.


